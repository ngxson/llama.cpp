# Development Documentation: `clip.cpp` and `libmtmd`

## `clip.cpp`

The `clip.cpp` library provides a low-level interface for interacting with vision models.

**Core Workflow:**

1. An image is provided as a `clip_image_u8` structure, representing a raw RGB bitmap.
2. The image undergoes preprocessing via `clip_image_preprocess`. This results in a `clip_image_f32_batch`, which can contain one or more processed `clip_image_f32` images.
3. The `clip_image_batch_encode` function encodes the `clip_image_f32_batch`, returning a `float *` pointer to the resulting image embeddings.

These output embeddings can then be passed to a multimodal language model.

### Internal Concepts

Key terms:

- **Image**: The input raw RGB bitmap.
- **Slice**: A cropped portion of the input image. This technique is notably used in models like [LLaVA-UHD](https://github.com/thunlp/LLaVA-UHD) to handle high-resolution inputs by dividing them into smaller parts.
- **Patch**: A small, fixed-size segment of the image (or slice) generated by the initial convolutional layer(s), as described in the original [Vision Transformer (ViT) paper](https://arxiv.org/abs/2010.11929). Patches are the fundamental units processed by the transformer layers.

*Note: Some implementations might use "slice" and "patch" interchangeably. This documentation adheres to the definitions above.*

### Preprocessing Strategies

The preprocessing step uses standard image manipulation techniques like cropping, padding, and resizing. There are four primary strategies:

1. **Single Slice, Fixed Size:**
    - The entire image is resized to the model's required input resolution (e.g., 336x336).
    - Padding is added if the original aspect ratio doesn't match the target square ratio.
    - *Examples: LLaVA 1.5, Gemma 3*
2. **Single Slice, Dynamic Size:**
    - The image is resized so its dimensions are the nearest multiples of the model's patch size.
    - *Examples: Qwen2VL, Pixtral*
3. **Multiple Slices, Fixed Size:**
    - The image is divided into multiple fixed-size slices (e.g., one high-res, several low-res). Each slice is processed independently.
    - Introduced by [LLaVA-UHD](https://github.com/thunlp/LLaVA-UHD).
    - *Example: MiniCPM-V*
4. **Multiple Slices, Dynamic Size:**
    - The image is divided into multiple slices, each potentially resized dynamically based on patch size multiples.
    - *Example: Qwen2.5VL*
    - *(TODO: Add more details)*

## `libmtmd`

TODO
